{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "134fa8d5-5e2f-4311-bd52-f0da0e758565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d118f908-36eb-4a37-915f-c0af0a5bf43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "data_dir = '~/data'\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# MNIST Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std of MNIST\n",
    "])\n",
    "train_data = datasets.MNIST(root = data_dir, train = True, transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "test_data = datasets.MNIST(root = data_dir, train = False , transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "363a83a5-aa3d-4174-b835-a700b76b679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "def train(model, loss_fn, optimizer, train_loader, test_loader, batch_size, num_epochs, device, conv):\n",
    "    total_time = 0;\n",
    "    losses = [[], [], []]\n",
    "    if device is not None:\n",
    "        model.to(device)\n",
    "    else:\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        print(device)\n",
    "        model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = perf_counter()\n",
    "        tr_loss_average = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            if conv:\n",
    "                images = images.view(-1, 1, 28, 28)\n",
    "            else:\n",
    "                images = images.view(-1, input_size)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            tr_loss = loss_fn(outputs, labels)\n",
    "            tr_loss_average += tr_loss.item()\n",
    "            tr_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                v_loss_average = 0\n",
    "                count_va = 0\n",
    "                for _, data in enumerate(test_loader, 0):\n",
    "                    images, labels = data[0].to(device), data[1].to(device)\n",
    "                    if conv:\n",
    "                        images = images.view(-1, 1, 28, 28)\n",
    "                    else:\n",
    "                        images = images.view(-1, input_size)\n",
    "                    outputs = model(images)\n",
    "                    v_loss_average += loss_fn(outputs, labels).item()\n",
    "                    count_va += 1\n",
    "\n",
    "                tr_loss_average /= 100\n",
    "                v_loss_average /= count_va\n",
    "                losses[0].append((epoch) * 1875 + (i+1))\n",
    "                losses[1].append(tr_loss_average)\n",
    "                losses[2].append(v_loss_average)\n",
    "                print('Epoch [%d/%d], Step [%d/%d], Train Loss: %.4f, Val Loss: %.4f'\n",
    "                            %(epoch+1, num_epochs, i+1,\n",
    "                            len(train_loader), tr_loss_average, v_loss_average))\n",
    "                tr_loss_average = 0\n",
    "\n",
    "        stop_time = perf_counter()\n",
    "        #val_acc = test_accuracy(model, test_loader, 784, device, conv)\n",
    "        #train_acc = test_accuracy(model, train_loader, 784, device, conv)\n",
    "        time = stop_time - start_time\n",
    "        #print('Epoch [%d/%d] End. Duration %.4f seconds. Train Acc: %.4f, Val Acc: %.4f'\n",
    "        print('Epoch [%d/%d] End. Duration %.4f seconds.' %(epoch+1, num_epochs, time))\n",
    "                            #%(epoch+1, num_epochs, time, train_acc, val_acc))\n",
    "        total_time += time\n",
    "\n",
    "    return (losses, total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5929daf3-6c97-4667-8922-5cc76056289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/1875], Train Loss: 1.2853, Val Loss: 0.3973\n",
      "Epoch [1/10], Step [200/1875], Train Loss: 0.2883, Val Loss: 0.2743\n",
      "Epoch [1/10], Step [300/1875], Train Loss: 0.2510, Val Loss: 0.2002\n",
      "Epoch [1/10], Step [400/1875], Train Loss: 0.1899, Val Loss: 0.2006\n",
      "Epoch [1/10], Step [500/1875], Train Loss: 0.1600, Val Loss: 0.1329\n",
      "Epoch [1/10], Step [600/1875], Train Loss: 0.1154, Val Loss: 0.0863\n",
      "Epoch [1/10], Step [700/1875], Train Loss: 0.1103, Val Loss: 0.1194\n",
      "Epoch [1/10], Step [800/1875], Train Loss: 0.1009, Val Loss: 0.0849\n",
      "Epoch [1/10], Step [900/1875], Train Loss: 0.1042, Val Loss: 0.0816\n",
      "Epoch [1/10], Step [1000/1875], Train Loss: 0.1006, Val Loss: 0.0734\n",
      "Epoch [1/10], Step [1100/1875], Train Loss: 0.0851, Val Loss: 0.0900\n",
      "Epoch [1/10], Step [1200/1875], Train Loss: 0.0927, Val Loss: 0.0712\n",
      "Epoch [1/10], Step [1300/1875], Train Loss: 0.0815, Val Loss: 0.0824\n",
      "Epoch [1/10], Step [1400/1875], Train Loss: 0.0789, Val Loss: 0.0678\n",
      "Epoch [1/10], Step [1500/1875], Train Loss: 0.0915, Val Loss: 0.0849\n",
      "Epoch [1/10], Step [1600/1875], Train Loss: 0.0852, Val Loss: 0.0588\n",
      "Epoch [1/10], Step [1700/1875], Train Loss: 0.0710, Val Loss: 0.0554\n",
      "Epoch [1/10], Step [1800/1875], Train Loss: 0.0592, Val Loss: 0.0523\n",
      "Epoch [1/10] End. Duration 13.9221 seconds.\n",
      "Epoch [2/10], Step [100/1875], Train Loss: 0.0638, Val Loss: 0.0465\n",
      "Epoch [2/10], Step [200/1875], Train Loss: 0.0584, Val Loss: 0.0562\n",
      "Epoch [2/10], Step [300/1875], Train Loss: 0.0735, Val Loss: 0.0717\n",
      "Epoch [2/10], Step [400/1875], Train Loss: 0.0544, Val Loss: 0.0689\n",
      "Epoch [2/10], Step [500/1875], Train Loss: 0.0556, Val Loss: 0.0535\n",
      "Epoch [2/10], Step [600/1875], Train Loss: 0.0507, Val Loss: 0.0414\n",
      "Epoch [2/10], Step [700/1875], Train Loss: 0.0390, Val Loss: 0.0385\n",
      "Epoch [2/10], Step [800/1875], Train Loss: 0.0400, Val Loss: 0.0425\n",
      "Epoch [2/10], Step [900/1875], Train Loss: 0.0567, Val Loss: 0.0453\n",
      "Epoch [2/10], Step [1000/1875], Train Loss: 0.0435, Val Loss: 0.0411\n",
      "Epoch [2/10], Step [1100/1875], Train Loss: 0.0490, Val Loss: 0.0429\n",
      "Epoch [2/10], Step [1200/1875], Train Loss: 0.0511, Val Loss: 0.0518\n",
      "Epoch [2/10], Step [1300/1875], Train Loss: 0.0506, Val Loss: 0.0526\n",
      "Epoch [2/10], Step [1400/1875], Train Loss: 0.0430, Val Loss: 0.0537\n",
      "Epoch [2/10], Step [1500/1875], Train Loss: 0.0509, Val Loss: 0.0534\n",
      "Epoch [2/10], Step [1600/1875], Train Loss: 0.0446, Val Loss: 0.0432\n",
      "Epoch [2/10], Step [1700/1875], Train Loss: 0.0458, Val Loss: 0.0438\n",
      "Epoch [2/10], Step [1800/1875], Train Loss: 0.0352, Val Loss: 0.0353\n",
      "Epoch [2/10] End. Duration 13.7463 seconds.\n",
      "Epoch [3/10], Step [100/1875], Train Loss: 0.0408, Val Loss: 0.0349\n",
      "Epoch [3/10], Step [200/1875], Train Loss: 0.0356, Val Loss: 0.0446\n",
      "Epoch [3/10], Step [300/1875], Train Loss: 0.0434, Val Loss: 0.0451\n",
      "Epoch [3/10], Step [400/1875], Train Loss: 0.0299, Val Loss: 0.0382\n",
      "Epoch [3/10], Step [500/1875], Train Loss: 0.0303, Val Loss: 0.0350\n",
      "Epoch [3/10], Step [600/1875], Train Loss: 0.0313, Val Loss: 0.0332\n",
      "Epoch [3/10], Step [700/1875], Train Loss: 0.0226, Val Loss: 0.0317\n",
      "Epoch [3/10], Step [800/1875], Train Loss: 0.0251, Val Loss: 0.0331\n",
      "Epoch [3/10], Step [900/1875], Train Loss: 0.0370, Val Loss: 0.0309\n",
      "Epoch [3/10], Step [1000/1875], Train Loss: 0.0257, Val Loss: 0.0366\n",
      "Epoch [3/10], Step [1100/1875], Train Loss: 0.0345, Val Loss: 0.0358\n",
      "Epoch [3/10], Step [1200/1875], Train Loss: 0.0364, Val Loss: 0.0441\n",
      "Epoch [3/10], Step [1300/1875], Train Loss: 0.0387, Val Loss: 0.0436\n",
      "Epoch [3/10], Step [1400/1875], Train Loss: 0.0282, Val Loss: 0.0405\n",
      "Epoch [3/10], Step [1500/1875], Train Loss: 0.0318, Val Loss: 0.0484\n",
      "Epoch [3/10], Step [1600/1875], Train Loss: 0.0343, Val Loss: 0.0654\n",
      "Epoch [3/10], Step [1700/1875], Train Loss: 0.0367, Val Loss: 0.0447\n",
      "Epoch [3/10], Step [1800/1875], Train Loss: 0.0199, Val Loss: 0.0322\n",
      "Epoch [3/10] End. Duration 13.8861 seconds.\n",
      "Epoch [4/10], Step [100/1875], Train Loss: 0.0288, Val Loss: 0.0319\n",
      "Epoch [4/10], Step [200/1875], Train Loss: 0.0256, Val Loss: 0.0368\n",
      "Epoch [4/10], Step [300/1875], Train Loss: 0.0266, Val Loss: 0.0311\n",
      "Epoch [4/10], Step [400/1875], Train Loss: 0.0168, Val Loss: 0.0315\n",
      "Epoch [4/10], Step [500/1875], Train Loss: 0.0147, Val Loss: 0.0243\n",
      "Epoch [4/10], Step [600/1875], Train Loss: 0.0182, Val Loss: 0.0328\n",
      "Epoch [4/10], Step [700/1875], Train Loss: 0.0182, Val Loss: 0.0290\n",
      "Epoch [4/10], Step [800/1875], Train Loss: 0.0172, Val Loss: 0.0340\n",
      "Epoch [4/10], Step [900/1875], Train Loss: 0.0240, Val Loss: 0.0293\n",
      "Epoch [4/10], Step [1000/1875], Train Loss: 0.0176, Val Loss: 0.0401\n",
      "Epoch [4/10], Step [1100/1875], Train Loss: 0.0233, Val Loss: 0.0328\n",
      "Epoch [4/10], Step [1200/1875], Train Loss: 0.0269, Val Loss: 0.0343\n",
      "Epoch [4/10], Step [1300/1875], Train Loss: 0.0268, Val Loss: 0.0427\n",
      "Epoch [4/10], Step [1400/1875], Train Loss: 0.0258, Val Loss: 0.0417\n",
      "Epoch [4/10], Step [1500/1875], Train Loss: 0.0211, Val Loss: 0.0418\n",
      "Epoch [4/10], Step [1600/1875], Train Loss: 0.0185, Val Loss: 0.0438\n",
      "Epoch [4/10], Step [1700/1875], Train Loss: 0.0214, Val Loss: 0.0413\n",
      "Epoch [4/10], Step [1800/1875], Train Loss: 0.0075, Val Loss: 0.0294\n",
      "Epoch [4/10] End. Duration 13.2887 seconds.\n",
      "Epoch [5/10], Step [100/1875], Train Loss: 0.0193, Val Loss: 0.0337\n",
      "Epoch [5/10], Step [200/1875], Train Loss: 0.0195, Val Loss: 0.0370\n",
      "Epoch [5/10], Step [300/1875], Train Loss: 0.0203, Val Loss: 0.0350\n",
      "Epoch [5/10], Step [400/1875], Train Loss: 0.0133, Val Loss: 0.0302\n",
      "Epoch [5/10], Step [500/1875], Train Loss: 0.0091, Val Loss: 0.0238\n",
      "Epoch [5/10], Step [600/1875], Train Loss: 0.0153, Val Loss: 0.0286\n",
      "Epoch [5/10], Step [700/1875], Train Loss: 0.0170, Val Loss: 0.0380\n",
      "Epoch [5/10], Step [800/1875], Train Loss: 0.0137, Val Loss: 0.0325\n",
      "Epoch [5/10], Step [900/1875], Train Loss: 0.0209, Val Loss: 0.0267\n",
      "Epoch [5/10], Step [1000/1875], Train Loss: 0.0116, Val Loss: 0.0349\n",
      "Epoch [5/10], Step [1100/1875], Train Loss: 0.0204, Val Loss: 0.0292\n",
      "Epoch [5/10], Step [1200/1875], Train Loss: 0.0197, Val Loss: 0.0379\n",
      "Epoch [5/10], Step [1300/1875], Train Loss: 0.0159, Val Loss: 0.0435\n",
      "Epoch [5/10], Step [1400/1875], Train Loss: 0.0171, Val Loss: 0.0275\n",
      "Epoch [5/10], Step [1500/1875], Train Loss: 0.0139, Val Loss: 0.0355\n",
      "Epoch [5/10], Step [1600/1875], Train Loss: 0.0119, Val Loss: 0.0371\n",
      "Epoch [5/10], Step [1700/1875], Train Loss: 0.0177, Val Loss: 0.0446\n",
      "Epoch [5/10], Step [1800/1875], Train Loss: 0.0059, Val Loss: 0.0294\n",
      "Epoch [5/10] End. Duration 13.4733 seconds.\n",
      "Epoch [6/10], Step [100/1875], Train Loss: 0.0169, Val Loss: 0.0352\n",
      "Epoch [6/10], Step [200/1875], Train Loss: 0.0137, Val Loss: 0.0338\n",
      "Epoch [6/10], Step [300/1875], Train Loss: 0.0161, Val Loss: 0.0368\n",
      "Epoch [6/10], Step [400/1875], Train Loss: 0.0095, Val Loss: 0.0344\n",
      "Epoch [6/10], Step [500/1875], Train Loss: 0.0084, Val Loss: 0.0246\n",
      "Epoch [6/10], Step [600/1875], Train Loss: 0.0059, Val Loss: 0.0304\n",
      "Epoch [6/10], Step [700/1875], Train Loss: 0.0099, Val Loss: 0.0281\n",
      "Epoch [6/10], Step [800/1875], Train Loss: 0.0092, Val Loss: 0.0271\n",
      "Epoch [6/10], Step [900/1875], Train Loss: 0.0114, Val Loss: 0.0311\n",
      "Epoch [6/10], Step [1000/1875], Train Loss: 0.0069, Val Loss: 0.0423\n",
      "Epoch [6/10], Step [1100/1875], Train Loss: 0.0133, Val Loss: 0.0317\n",
      "Epoch [6/10], Step [1200/1875], Train Loss: 0.0133, Val Loss: 0.0299\n",
      "Epoch [6/10], Step [1300/1875], Train Loss: 0.0197, Val Loss: 0.0370\n",
      "Epoch [6/10], Step [1400/1875], Train Loss: 0.0146, Val Loss: 0.0475\n",
      "Epoch [6/10], Step [1500/1875], Train Loss: 0.0122, Val Loss: 0.0450\n",
      "Epoch [6/10], Step [1600/1875], Train Loss: 0.0054, Val Loss: 0.0324\n",
      "Epoch [6/10], Step [1700/1875], Train Loss: 0.0163, Val Loss: 0.0370\n",
      "Epoch [6/10], Step [1800/1875], Train Loss: 0.0086, Val Loss: 0.0282\n",
      "Epoch [6/10] End. Duration 13.4215 seconds.\n",
      "Epoch [7/10], Step [100/1875], Train Loss: 0.0078, Val Loss: 0.0317\n",
      "Epoch [7/10], Step [200/1875], Train Loss: 0.0082, Val Loss: 0.0310\n",
      "Epoch [7/10], Step [300/1875], Train Loss: 0.0143, Val Loss: 0.0380\n",
      "Epoch [7/10], Step [400/1875], Train Loss: 0.0119, Val Loss: 0.0326\n",
      "Epoch [7/10], Step [500/1875], Train Loss: 0.0043, Val Loss: 0.0240\n",
      "Epoch [7/10], Step [600/1875], Train Loss: 0.0093, Val Loss: 0.0386\n",
      "Epoch [7/10], Step [700/1875], Train Loss: 0.0070, Val Loss: 0.0286\n",
      "Epoch [7/10], Step [800/1875], Train Loss: 0.0067, Val Loss: 0.0304\n",
      "Epoch [7/10], Step [900/1875], Train Loss: 0.0072, Val Loss: 0.0286\n",
      "Epoch [7/10], Step [1000/1875], Train Loss: 0.0102, Val Loss: 0.0348\n",
      "Epoch [7/10], Step [1100/1875], Train Loss: 0.0115, Val Loss: 0.0378\n",
      "Epoch [7/10], Step [1200/1875], Train Loss: 0.0081, Val Loss: 0.0333\n",
      "Epoch [7/10], Step [1300/1875], Train Loss: 0.0089, Val Loss: 0.0371\n",
      "Epoch [7/10], Step [1400/1875], Train Loss: 0.0056, Val Loss: 0.0435\n",
      "Epoch [7/10], Step [1500/1875], Train Loss: 0.0141, Val Loss: 0.0400\n",
      "Epoch [7/10], Step [1600/1875], Train Loss: 0.0092, Val Loss: 0.0270\n",
      "Epoch [7/10], Step [1700/1875], Train Loss: 0.0111, Val Loss: 0.0389\n",
      "Epoch [7/10], Step [1800/1875], Train Loss: 0.0060, Val Loss: 0.0343\n",
      "Epoch [7/10] End. Duration 13.4606 seconds.\n",
      "Epoch [8/10], Step [100/1875], Train Loss: 0.0072, Val Loss: 0.0294\n",
      "Epoch [8/10], Step [200/1875], Train Loss: 0.0077, Val Loss: 0.0410\n",
      "Epoch [8/10], Step [300/1875], Train Loss: 0.0088, Val Loss: 0.0434\n",
      "Epoch [8/10], Step [400/1875], Train Loss: 0.0071, Val Loss: 0.0266\n",
      "Epoch [8/10], Step [500/1875], Train Loss: 0.0018, Val Loss: 0.0248\n",
      "Epoch [8/10], Step [600/1875], Train Loss: 0.0040, Val Loss: 0.0307\n",
      "Epoch [8/10], Step [700/1875], Train Loss: 0.0066, Val Loss: 0.0325\n",
      "Epoch [8/10], Step [800/1875], Train Loss: 0.0034, Val Loss: 0.0273\n",
      "Epoch [8/10], Step [900/1875], Train Loss: 0.0110, Val Loss: 0.0323\n",
      "Epoch [8/10], Step [1000/1875], Train Loss: 0.0044, Val Loss: 0.0449\n",
      "Epoch [8/10], Step [1100/1875], Train Loss: 0.0129, Val Loss: 0.0387\n",
      "Epoch [8/10], Step [1200/1875], Train Loss: 0.0084, Val Loss: 0.0324\n",
      "Epoch [8/10], Step [1300/1875], Train Loss: 0.0061, Val Loss: 0.0298\n",
      "Epoch [8/10], Step [1400/1875], Train Loss: 0.0052, Val Loss: 0.0371\n",
      "Epoch [8/10], Step [1500/1875], Train Loss: 0.0129, Val Loss: 0.0396\n",
      "Epoch [8/10], Step [1600/1875], Train Loss: 0.0045, Val Loss: 0.0322\n",
      "Epoch [8/10], Step [1700/1875], Train Loss: 0.0073, Val Loss: 0.0349\n",
      "Epoch [8/10], Step [1800/1875], Train Loss: 0.0070, Val Loss: 0.0424\n",
      "Epoch [8/10] End. Duration 13.5780 seconds.\n",
      "Epoch [9/10], Step [100/1875], Train Loss: 0.0045, Val Loss: 0.0334\n",
      "Epoch [9/10], Step [200/1875], Train Loss: 0.0042, Val Loss: 0.0283\n",
      "Epoch [9/10], Step [300/1875], Train Loss: 0.0051, Val Loss: 0.0325\n",
      "Epoch [9/10], Step [400/1875], Train Loss: 0.0055, Val Loss: 0.0442\n",
      "Epoch [9/10], Step [500/1875], Train Loss: 0.0041, Val Loss: 0.0346\n",
      "Epoch [9/10], Step [600/1875], Train Loss: 0.0052, Val Loss: 0.0330\n",
      "Epoch [9/10], Step [700/1875], Train Loss: 0.0030, Val Loss: 0.0306\n",
      "Epoch [9/10], Step [800/1875], Train Loss: 0.0022, Val Loss: 0.0277\n",
      "Epoch [9/10], Step [900/1875], Train Loss: 0.0065, Val Loss: 0.0361\n",
      "Epoch [9/10], Step [1000/1875], Train Loss: 0.0075, Val Loss: 0.0361\n",
      "Epoch [9/10], Step [1100/1875], Train Loss: 0.0087, Val Loss: 0.0410\n",
      "Epoch [9/10], Step [1200/1875], Train Loss: 0.0126, Val Loss: 0.0373\n",
      "Epoch [9/10], Step [1300/1875], Train Loss: 0.0122, Val Loss: 0.0359\n",
      "Epoch [9/10], Step [1400/1875], Train Loss: 0.0028, Val Loss: 0.0436\n",
      "Epoch [9/10], Step [1500/1875], Train Loss: 0.0067, Val Loss: 0.0427\n",
      "Epoch [9/10], Step [1600/1875], Train Loss: 0.0101, Val Loss: 0.0446\n",
      "Epoch [9/10], Step [1700/1875], Train Loss: 0.0166, Val Loss: 0.0456\n",
      "Epoch [9/10], Step [1800/1875], Train Loss: 0.0039, Val Loss: 0.0338\n",
      "Epoch [9/10] End. Duration 13.2128 seconds.\n",
      "Epoch [10/10], Step [100/1875], Train Loss: 0.0022, Val Loss: 0.0255\n",
      "Epoch [10/10], Step [200/1875], Train Loss: 0.0021, Val Loss: 0.0271\n",
      "Epoch [10/10], Step [300/1875], Train Loss: 0.0055, Val Loss: 0.0389\n",
      "Epoch [10/10], Step [400/1875], Train Loss: 0.0051, Val Loss: 0.0277\n",
      "Epoch [10/10], Step [500/1875], Train Loss: 0.0029, Val Loss: 0.0247\n",
      "Epoch [10/10], Step [600/1875], Train Loss: 0.0024, Val Loss: 0.0322\n",
      "Epoch [10/10], Step [700/1875], Train Loss: 0.0043, Val Loss: 0.0357\n",
      "Epoch [10/10], Step [800/1875], Train Loss: 0.0059, Val Loss: 0.0375\n",
      "Epoch [10/10], Step [900/1875], Train Loss: 0.0058, Val Loss: 0.0506\n",
      "Epoch [10/10], Step [1000/1875], Train Loss: 0.0028, Val Loss: 0.0355\n",
      "Epoch [10/10], Step [1100/1875], Train Loss: 0.0052, Val Loss: 0.0543\n",
      "Epoch [10/10], Step [1200/1875], Train Loss: 0.0044, Val Loss: 0.0348\n",
      "Epoch [10/10], Step [1300/1875], Train Loss: 0.0042, Val Loss: 0.0332\n",
      "Epoch [10/10], Step [1400/1875], Train Loss: 0.0035, Val Loss: 0.0355\n",
      "Epoch [10/10], Step [1500/1875], Train Loss: 0.0043, Val Loss: 0.0391\n",
      "Epoch [10/10], Step [1600/1875], Train Loss: 0.0036, Val Loss: 0.0458\n",
      "Epoch [10/10], Step [1700/1875], Train Loss: 0.0060, Val Loss: 0.0398\n",
      "Epoch [10/10], Step [1800/1875], Train Loss: 0.0058, Val Loss: 0.0443\n",
      "Epoch [10/10] End. Duration 13.6827 seconds.\n",
      "Total Training Time in Seconds:  135.67214603300272  seconds\n"
     ]
    }
   ],
   "source": [
    "# Define 5-Layer Network w/ batch normalization\n",
    "class Net5(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Net5,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2, stride = 1)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding = 2)\n",
    "        self.fc1 = nn.Linear(14*14*64, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.pooling(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = torch.flatten(out, start_dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# ...\n",
    "\n",
    "# Net5\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "lr = 0.0003\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "net = Net5(input_size, num_classes)\n",
    "for param in net.parameters():\n",
    "    nn.init.normal_(param, mean=0, std=0.01)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "losses_net5, total_time = train(net, loss_function, optimizer, train_loader, test_loader, batch_size, num_epochs, device, True)\n",
    "\n",
    "print(\"Total Training Time in Seconds: \", total_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dff0de13-2d6d-4920-9962-df39c6aef37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss:  0.04888822506901875 and Total Accuracy:  98.77 %\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_loader, loss_fn, device, conv, input_size=784):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given data_loader.\n",
    "    Returns average loss and accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()  # set model to eval mode\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            if conv:\n",
    "                images = images.view(-1, 1, 28, 28)\n",
    "            else:\n",
    "                images = images.view(-1, input_size)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "loss, accuracy = evaluate(net, test_loader, loss_function, device, True)\n",
    "\n",
    "print(\"Total Loss: \", loss, \"and Total Accuracy: \", accuracy * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb68f7-6c2a-4edc-b85b-defd021f0985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
