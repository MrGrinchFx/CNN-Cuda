{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a00935f-32f8-4949-9d70-acba8947d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6fe5eeb-1241-4a10-b39d-1b62c5b83068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: torch.Size([60000, 1, 28, 28])\n",
      "Train Data Type: torch.float32\n",
      "Test Data Shape: torch.Size([10000, 1, 28, 28])\n",
      "Test Data Type: torch.float32\n",
      "Iters per epoch: 937\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "data_dir = '~/data'\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# MNIST Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std of MNIST\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root=data_dir, train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Pre-allocate tensors of the appropriate size\n",
    "train_data = torch.zeros(len(train_dataset), 1, 28, 28)\n",
    "train_labels = torch.zeros(len(train_dataset), dtype=torch.long)\n",
    "test_data = torch.zeros(len(test_dataset), 1, 28, 28)\n",
    "test_labels = torch.zeros(len(test_dataset), dtype=torch.long)\n",
    "\n",
    "# Load all training data into RAM\n",
    "for idx, (data, label) in enumerate(train_loader):\n",
    "    start_idx = idx * batch_size\n",
    "    end_idx = start_idx + data.size(0)\n",
    "    train_data[start_idx:end_idx] = data\n",
    "    train_labels[start_idx:end_idx] = label\n",
    "\n",
    "print('Train Data Shape:', train_data.shape)\n",
    "print('Train Data Type:', train_data.dtype)\n",
    "\n",
    "# Load all test data into RAM\n",
    "for idx, (data, label) in enumerate(test_loader):\n",
    "    start_idx = idx * batch_size\n",
    "    end_idx = start_idx + data.size(0)\n",
    "    test_data[start_idx:end_idx] = data\n",
    "    test_labels[start_idx:end_idx] = label\n",
    "\n",
    "print('Test Data Shape:', test_data.shape)\n",
    "print('Test Data Type:', test_data.dtype)\n",
    "\n",
    "iters_per_epoch = len(train_dataset) // batch_size\n",
    "print('Iters per epoch:', iters_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d42d78a0-b6d5-43e8-ab43-71de0443c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "# class Net5(nn.Module):\n",
    "#     def __init__(self, input_size, num_classes):\n",
    "#         super(Net5,self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2, stride = 1)\n",
    "#         self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding = 2)\n",
    "#         self.fc1 = nn.Linear(14*14*64, 1024)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.pooling(out)\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = torch.flatten(out, start_dim=1)\n",
    "#         out = self.fc1(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc2(out)\n",
    "#         return out\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(batch_size, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "   \n",
    "model = MLP(in_features=784, hidden_features=256, num_classes=10).to('cuda')\n",
    "# model = torch.compile(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e17ded-d246-476a-92cf-99c1fb8d774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 1, Loss: 1.0183792114257812\n",
      "Iteration Time: 1.0791 ms\n",
      "Epoch: 1, Iter: 100, Loss: 1.2778819799423218\n",
      "Iteration Time: 0.5140 ms\n",
      "Epoch: 1, Iter: 200, Loss: 0.9079237580299377\n",
      "Iteration Time: 0.5894 ms\n",
      "Epoch: 1, Iter: 300, Loss: 0.9549307227134705\n",
      "Iteration Time: 0.5140 ms\n",
      "Epoch: 1, Iter: 400, Loss: 0.8083716034889221\n",
      "Iteration Time: 0.4892 ms\n",
      "Epoch: 1, Iter: 500, Loss: 0.8126129508018494\n",
      "Iteration Time: 0.5009 ms\n",
      "Epoch: 1, Iter: 600, Loss: 0.9028329253196716\n",
      "Iteration Time: 0.6452 ms\n",
      "Epoch: 1, Iter: 700, Loss: 0.6639201641082764\n",
      "Iteration Time: 0.4823 ms\n",
      "Epoch: 1, Iter: 800, Loss: 0.79194575548172\n",
      "Iteration Time: 0.5214 ms\n",
      "Epoch: 1, Iter: 900, Loss: 0.9863045811653137\n",
      "Iteration Time: 1.0068 ms\n",
      "Average Batch Accuracy: 85.77%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# epochs = 2\n",
    "# Training the model\n",
    "def train(model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i in range(iters_per_epoch):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        data = train_data[i*batch_size:(i+1)*batch_size].to('cuda')\n",
    "        target = train_labels[i*batch_size:(i+1)*batch_size].to('cuda')\n",
    "        start = time.time()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        end = time.time()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99 or i == 0:\n",
    "            print(f'Epoch: {epoch+1}, Iter: {i+1}, Loss: {loss}')\n",
    "            print(f'Iteration Time: {(end - start) * 1e3:.4f} ms')\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Evaluation function to report average batch accuracy using the loaded test data\n",
    "def evaluate(model, test_data, test_labels):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_batch_accuracy = torch.tensor(0.0, device=device)\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_data) // batch_size):\n",
    "            data = test_data[i * batch_size: (i + 1) * batch_size].to(device)\n",
    "            target = test_labels[i * batch_size: (i + 1) * batch_size].to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_batch = (predicted == target).sum().item()\n",
    "            total_batch = target.size(0)\n",
    "            if total_batch != 0:  # Check to avoid division by zero\n",
    "                batch_accuracy = correct_batch / total_batch\n",
    "                total_batch_accuracy += batch_accuracy\n",
    "                num_batches += 1\n",
    "    \n",
    "    avg_batch_accuracy = total_batch_accuracy / num_batches\n",
    "    print(f'Average Batch Accuracy: {avg_batch_accuracy * 100:.2f}%')\n",
    "\n",
    "# Main\n",
    "for epoch in range(1):\n",
    "    train(model, criterion, optimizer, epoch)\n",
    "    evaluate(model, test_data, test_labels)\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab7db8-de28-4eb0-9130-1f7f2e507147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
